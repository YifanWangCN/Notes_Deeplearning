{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fdadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import testCases\n",
    "import lr_utils\n",
    "from dnn_utils import sigmoid,sigmoid_backward,relu,relu_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d2bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定随机种子\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db525e61",
   "metadata": {},
   "source": [
    "### 首先是两层的神经网络，对于一个两层的神经网络结构而言，模型结构为线性，Relu，线性，sigmoid函数\n",
    "在这里对神经网络中的维度进行一个简单说明\n",
    "\n",
    "如果输入的参数维度为（3，1）；第一层的节点个数为2个的话。W1的维度为（2，3）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740d6c8",
   "metadata": {},
   "source": [
    "### 下面的函数是为了初始化多层网络参数而使用的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15eacb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layers_dims):\n",
    "    \"\"\"\n",
    "    此函数是为了初始化多层网络参数而使用的函数。\n",
    "    参数：\n",
    "        layers_dims - 包含我们网络中每个图层的节点数量的列表\n",
    "    \n",
    "    返回：\n",
    "        parameters - 包含参数“W1”，“b1”，...，“WL”，“bL”的字典：\n",
    "                     W1 - 权重矩阵，维度为（layers_dims [1]，layers_dims [1-1]）\n",
    "                     bl - 偏向量，维度为（layers_dims [1]，1）\n",
    "    \"\"\"\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layers_dims)\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) / np.sqrt(layers_dims[l - 1])\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "        \n",
    "        #确保我要的数据的格式是正确的\n",
    "        assert(parameters[\"W\" + str(l)].shape == (layers_dims[l], layers_dims[l-1]))\n",
    "        assert(parameters[\"b\" + str(l)].shape == (layers_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86711ccd",
   "metadata": {},
   "source": [
    "### 构建向前传播函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f9cc585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播，线性部分的计算函数\n",
    "def linear_forward(A,W,b):\n",
    "    \"\"\"\n",
    "    实现前向传播的线性部分。\n",
    "\n",
    "    参数：\n",
    "        A - 来自上一层（或输入数据）的激活，维度为(上一层的节点数量，示例的数量）\n",
    "        W - 权重矩阵，numpy数组，维度为（当前图层的节点数量，前一图层的节点数量）\n",
    "        b - 偏向量，numpy向量，维度为（当前图层节点数量，1）\n",
    "\n",
    "    返回：\n",
    "         Z - 激活功能的输入，也称为预激活参数\n",
    "         cache - 一个包含“A”，“W”和“b”的字典，存储这些变量以有效地计算后向传递\n",
    "    \"\"\"\n",
    "    Z = np.dot(W,A) + b\n",
    "    assert(Z.shape == (W.shape[0],A.shape[1]))\n",
    "    cache = (A,W,b)\n",
    "     \n",
    "    return Z,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61436176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播，激活函数部分的计算函数\n",
    "def linear_activation_forward(A_prev,W,b,activation):\n",
    "    \"\"\"\n",
    "    实现LINEAR-> ACTIVATION 这一层的前向传播\n",
    "\n",
    "    参数：\n",
    "        A_prev - 来自上一层（或输入层）的激活，维度为(上一层的节点数量，示例数）\n",
    "        W - 权重矩阵，numpy数组，维度为（当前层的节点数量，前一层的大小）\n",
    "        b - 偏向量，numpy阵列，维度为（当前层的节点数量，1）\n",
    "        activation - 选择在此层中使用的激活函数名，字符串类型，【\"sigmoid\" | \"relu\"】\n",
    "\n",
    "    返回：\n",
    "        A - 激活函数的输出，也称为激活后的值\n",
    "        cache - 一个包含“linear_cache”和“activation_cache”的字典，我们需要存储它以有效地计算后向传递\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert(A.shape == (W.shape[0],A_prev.shape[1]))\n",
    "    cache = (linear_cache,activation_cache)\n",
    "    \n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b746b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X,parameters):\n",
    "    \"\"\"\n",
    "    实现[LINEAR-> RELU] *（L-1） - > LINEAR-> SIGMOID计算前向传播，也就是多层网络的前向传播，为后面每一层都执行LINEAR和ACTIVATION\n",
    "    \n",
    "    参数：\n",
    "        X - 数据，numpy数组，维度为（输入节点数量，示例数）\n",
    "        parameters - initialize_parameters_deep（）的输出\n",
    "    \n",
    "    返回：\n",
    "        AL - 最后的激活值\n",
    "        caches - 包含以下内容的缓存列表：\n",
    "                 linear_relu_forward（）的每个cache（有L-1个，索引为从0到L-2）\n",
    "                 linear_sigmoid_forward（）的cache（只有一个，索引为L-1）\n",
    "    \"\"\"\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1,L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "    \n",
    "    return AL,caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbfd42b",
   "metadata": {},
   "source": [
    "### 计算成本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40997407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL,Y):\n",
    "    \"\"\"\n",
    "    实施等式（4）定义的成本函数。\n",
    "\n",
    "    参数：\n",
    "        AL - 与标签预测相对应的概率向量，维度为（1，示例数量）\n",
    "        Y - 标签向量（例如：如果不是猫，则为0，如果是猫则为1），维度为（1，数量）\n",
    "\n",
    "    返回：\n",
    "        cost - 交叉熵成本\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    cost = -np.sum(np.multiply(np.log(AL),Y) + np.multiply(np.log(1 - AL), 1 - Y)) / m\n",
    "        \n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb7f1cf",
   "metadata": {},
   "source": [
    "### 神经网络的反向传播\n",
    "这个部分是关键所在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e7adfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先是后向传播的线性部分\n",
    "def linear_backward(dZ,cache):\n",
    "    \"\"\"\n",
    "    为单层实现反向传播的线性部分（第L层）\n",
    "\n",
    "    参数：\n",
    "         dZ - 相对于（当前第l层的）线性输出的成本梯度\n",
    "         cache - 来自当前层前向传播的值的元组（A_prev，W，b）\n",
    "\n",
    "    返回：\n",
    "         dA_prev - 相对于激活（前一层l-1）的成本梯度，与A_prev维度相同\n",
    "         dW - 相对于W（当前层l）的成本梯度，与W的维度相同\n",
    "         db - 相对于b（当前层l）的成本梯度，与b维度相同\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = np.dot(dZ, A_prev.T) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5dc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA,cache,activation=\"relu\"):\n",
    "    \"\"\"\n",
    "    实现LINEAR-> ACTIVATION层的后向传播。\n",
    "    \n",
    "    参数：\n",
    "         dA - 当前层l的激活后的梯度值\n",
    "         cache - 我们存储的用于有效计算反向传播的值的元组（值为linear_cache，activation_cache）\n",
    "         activation - 要在此层中使用的激活函数名，字符串类型，【\"sigmoid\" | \"relu\"】\n",
    "    返回：\n",
    "         dA_prev - 相对于激活（前一层l-1）的成本梯度值，与A_prev维度相同\n",
    "         dW - 相对于W（当前层l）的成本梯度值，与W的维度相同\n",
    "         db - 相对于b（当前层l）的成本梯度值，与b的维度相同\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4289ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL,Y,caches):\n",
    "    \"\"\"\n",
    "    对[LINEAR-> RELU] *（L-1） - > LINEAR - > SIGMOID组执行反向传播，就是多层网络的向后传播\n",
    "    \n",
    "    参数：\n",
    "     AL - 概率向量，正向传播的输出（L_model_forward（））\n",
    "     Y - 标签向量（例如：如果不是猫，则为0，如果是猫则为1），维度为（1，数量）\n",
    "     caches - 包含以下内容的cache列表：\n",
    "                 linear_activation_forward（\"relu\"）的cache，不包含输出层\n",
    "                 linear_activation_forward（\"sigmoid\"）的cache\n",
    "    \n",
    "    返回：\n",
    "     grads - 具有梯度值的字典\n",
    "              grads [“dA”+ str（l）] = ...\n",
    "              grads [“dW”+ str（l）] = ...\n",
    "              grads [“db”+ str（l）] = ...\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, \"relu\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc57e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    使用梯度下降更新参数\n",
    "    \n",
    "    参数：\n",
    "     parameters - 包含你的参数的字典\n",
    "     grads - 包含梯度值的字典，是L_model_backward的输出\n",
    "    \n",
    "    返回：\n",
    "     parameters - 包含更新参数的字典\n",
    "                   参数[“W”+ str（l）] = ...\n",
    "                   参数[“b”+ str（l）] = ...\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2 #整除\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed4001be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False,isPlot=True):\n",
    "    \"\"\"\n",
    "    实现一个L层神经网络：[LINEAR-> RELU] *（L-1） - > LINEAR-> SIGMOID。\n",
    "    \n",
    "    参数：\n",
    "\t    X - 输入的数据，维度为(n_x，例子数)\n",
    "        Y - 标签，向量，0为非猫，1为猫，维度为(1,数量)\n",
    "        layers_dims - 层数的向量，维度为(n_y,n_h,···,n_h,n_y)\n",
    "        learning_rate - 学习率\n",
    "        num_iterations - 迭代的次数\n",
    "        print_cost - 是否打印成本值，每100次打印一次\n",
    "        isPlot - 是否绘制出误差值的图谱\n",
    "    \n",
    "    返回：\n",
    "     parameters - 模型学习的参数。 然后他们可以用来预测。\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    for i in range(0,num_iterations):\n",
    "        AL , caches = L_model_forward(X,parameters)\n",
    "        \n",
    "        cost = compute_cost(AL,Y)\n",
    "        \n",
    "        grads = L_model_backward(AL,Y,caches)\n",
    "        \n",
    "        parameters = update_parameters(parameters,grads,learning_rate)\n",
    "        \n",
    "        #打印成本值，如果print_cost=False则忽略\n",
    "        if i % 100 == 0:\n",
    "            #记录成本\n",
    "            costs.append(cost)\n",
    "            #是否打印成本值\n",
    "            if print_cost:\n",
    "                print(\"第\", i ,\"次迭代，成本值为：\" ,np.squeeze(cost))\n",
    "    #迭代完成，根据条件绘制图\n",
    "    if isPlot:\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946363f",
   "metadata": {},
   "source": [
    "### 加载训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80d6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes = lr_utils.load_dataset()\n",
    "\n",
    "train_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T \n",
    "test_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "\n",
    "train_x = train_x_flatten / 255\n",
    "train_y = train_set_y\n",
    "test_x = test_x_flatten / 255\n",
    "test_y = test_set_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31a35619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 次迭代，成本值为： 0.715731513413713\n",
      "第 100 次迭代，成本值为： 0.6747377593469114\n",
      "第 200 次迭代，成本值为： 0.6603365433622127\n",
      "第 300 次迭代，成本值为： 0.6462887802148751\n",
      "第 400 次迭代，成本值为： 0.6298131216927773\n",
      "第 500 次迭代，成本值为： 0.6060056229265339\n",
      "第 600 次迭代，成本值为： 0.5690041263975135\n",
      "第 700 次迭代，成本值为： 0.519796535043806\n",
      "第 800 次迭代，成本值为： 0.46415716786282285\n",
      "第 900 次迭代，成本值为： 0.40842030048298916\n",
      "第 1000 次迭代，成本值为： 0.3731549921606903\n",
      "第 1100 次迭代，成本值为： 0.30572374573047106\n",
      "第 1200 次迭代，成本值为： 0.26810152847740837\n",
      "第 1300 次迭代，成本值为： 0.23872474827672668\n",
      "第 1400 次迭代，成本值为： 0.20632263257914718\n",
      "第 1500 次迭代，成本值为： 0.17943886927493613\n",
      "第 1600 次迭代，成本值为： 0.1579873581880171\n",
      "第 1700 次迭代，成本值为： 0.14240413012274591\n",
      "第 1800 次迭代，成本值为： 0.1286516599788921\n",
      "第 1900 次迭代，成本值为： 0.11244314998166012\n",
      "第 2000 次迭代，成本值为： 0.08505631034985325\n",
      "第 2100 次迭代，成本值为： 0.05758391198618706\n",
      "第 2200 次迭代，成本值为： 0.04456753454700095\n",
      "第 2300 次迭代，成本值为： 0.03808275166600737\n",
      "第 2400 次迭代，成本值为： 0.034410749018423094\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加输入层一共五层的神经网络 最后一层是sigmoid激活函数\n",
    "\n",
    "layers_dims = [12288, 20, 7, 5, 1] #  5-layer model\n",
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True,isPlot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda19cb3",
   "metadata": {},
   "source": [
    "### 玄学的部分在于 我遇到了梯度消失的问题 我暂不清楚是怎么导致的 梯度消失的可能性有很多 比如初始的值过大，学习率过大等 \n",
    "重写代码就解决了 我完全不知道导致这个问题的原因是什么 非常奇怪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
